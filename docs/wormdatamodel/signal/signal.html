<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>wormdatamodel.signal.signal API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>wormdatamodel.signal.signal</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Authors: Milena Chakraverti-Wuerthwein and Francesco Randi

import numpy as np
import matplotlib.pyplot as plt
import warnings
import os
import pickle
from scipy.optimize import minimize
from copy import deepcopy as deepcopy
from datetime import datetime
import mistofrutta.struct.irrarray as irrarray
import wormdatamodel as wormdm
import savitzkygolay as sg
from sklearn.decomposition import FastICA

class Signal:
    &#39;&#39;&#39;Class representing signal extracted from recording. It supports irregular
    striding of the signal, useful for recordings with associated events, like
    optogenetics stimulations. The metadata about the irregular strides can be 
    obtained via the recording.get_events() method.
    
    The class provides some preprocessing functionalities, like 
    nan-interpolation, smoothing, and in the future will provide photobleaching
    correction, with the goal of abstracting all this away from the scripts
    analysing the signal.    
    &#39;&#39;&#39;

    nan_mask = np.zeros(1) # where nans
    data = np.empty((0,0)); # data array; either ndarray or irrarray
    info = [];
    which_skip = dict(zip([],[])); # which strides should be ignored
    
    maxY = np.empty((0))
    photobl_p = np.empty((0,0))
    photobl_n_params = 5
    
    logbook = &#34;&#34;
    
    description = &#34;_created from data_&#34;
    filename = &#34;signal.pickle&#34;
    
    def __init__(self, data, info, description = None, 
                 strides = [], stride_names = [], stride_skip = [[0]], 
                 preprocess = None, nan_interp = True, 
                 smooth = False, smooth_n=4, 
                 photobl_calc = False, photobl_appl = False,
                 corr_inst_photobl = False):
        &#39;&#39;&#39;Constructor for the class. 
        
        Parameters
        ----------
        data: numpy array
            2D array containing the data. The outermost axis has to be the one
            that gets strided irregularly.
        info: dict
            Dictionary containing the metadata about how the signal has been
            extracted from the frames.
        strides: list of numpy arrays (optional)
            Usually, the ones returned from recording.get_events().
            See documentation for the irregular array. Default: empty.
        stride_names: list of strings (optional)
            See documentation for the irregular array. Default: empty.
        stride_skip: list of integers (optional)
            Number of strides to skip at the beginning. Default: empty.
        preprocess: bool
            Apply the all the preprocessing to the signal. It does not control 
            the correction of instantaneous photobleaching. Default: False.     
        nan_interp: bool.
            Interpolate nans. Default: True.
        smooth: bool
            Smooth with a box of size smooth_n. Default: False.
        smooth_n: int
            Size of the smoothing box. Default: 4.
        photobl_calc: bool
            Calculate the photobleaching correction. Set this to True instead of
            photobl_appl if you are using the photobleaching correction for one
            of the ratiometric methods. Default: False.
        photobl_appl: bool
            Apply the photobleaching correction. If True, the photobleaching 
            correction will be calculated. Default: False.
        corr_inst_photobl: bool
            Detect and correct instantaneous photobleaching. Use only for the
            red signal. Default: False.
        &#39;&#39;&#39;

        self.data = data;
        self.info = info;
        if description is not None: self.description = description
        
        # Preprocessing
        self.nan_mask = np.isnan(self.data)
        self.maxY = np.zeros(self.data.shape[1])
        self.photobl_p = np.zeros((self.data.shape[1],5))
        
        self.smooth_n = smooth_n; # smoothing parameter
        if preprocess is not None:
            if preprocess:
                nan_interp = True
                smooth = True
                photobl_calc = True
                photobl_appl = True
            elif not preprocess:
                nan_interp = False
                smooth = False
                photobl_calc = False
                photobl_appl = False
        if photobl_appl: photobl_calc = True
        
        if nan_interp: self.data = self.interpolate_nans();
        if corr_inst_photobl: self.corr_inst_photobl();
        if photobl_calc: self.calc_photobl()
        if photobl_appl: self.appl_photobl()
        if smooth: self.data = self.smooth(smooth_n);
            
        
        # strides option allows you to construct an irregular array
        self.which_skip = dict(zip(stride_names,stride_skip))
        if len(strides) &gt; 0:
            
            # make sure that stride_names matches in size with the number stride arrays provided
            if len(stride_names) &gt; len(strides):
                warnings.warn(&#39;More stride names specified than stride arrays. Unused have been cut.&#39;);
                stride_names = stride_names[0:len(strides)]
            elif len(stride_names) &lt; len(strides):
                warnings.warn(&#39;Fewer stride names specified than stride arrays. &#39; + 
                &#39;Additional strides have been set to the default (thing_0, thing_1, ...).&#39;);
                for i in np.arange(len(strides) - len(stride_names)):
                    stride_names += [&#39;thing_&#39; + str(i)]
            
            data_uncut = np.copy(self.data)
            self.data = irrarray(data_uncut, strides, strideNames=stride_names)
            
            mask_uncut = np.copy(self.nan_mask)
            self.nan_mask = irrarray(mask_uncut, strides, strideNames=stride_names)
    
    
    @classmethod
    def from_file(cls,folder,filename,*args,**kwargs):
        &#39;&#39;&#39;Creates an instance of the class loading the data from file. If 
        filename ends with &#34;.txt&#34; the Signal object will be created from the 
        raw data. If the filename ends with &#34;.pickle&#34;, the function will load
        the data from the pickled file. If the filename does not end with either
        extension, the data will be loaded from the pickled file filename.pickle
        if present, otherwise from the raw filename.txt. 
        
        Parameters
        ----------
        folder: str
            Folder containing the file.
        filename: str
            Name of the file containing the signal array.
        *args, **kwargs
            Any other parameter to be passed to the constructor.
        &#39;&#39;&#39;
        
        if filename.split(&#34;.&#34;)[-1] == &#34;txt&#34;: 
            # read in data; rows = time, columns = neuron
            data, info = wormdm.signal.from_file(folder,filename)
            # adjusting the shape so that even if only one neuron, still has &#34;columns&#34;
            try:
                data.shape[1]
            except:
                data = np.copy(np.reshape(data,(data.shape[0],1)))
            
            inst = cls(data,info,&#34;.&#34;.join(filename.split(&#34;.&#34;)[:-1]),*args,**kwargs)
            return inst
            
        elif filename.split(&#34;.&#34;)[-1] == &#34;pickle&#34;:
            f = open(folder+filename,&#34;rb&#34;)
            inst = pickle.load(f)
            f.close()
            return inst
        else:
            if os.path.isfile(folder+filename+&#34;.pickle&#34;):
                f = open(folder+filename+&#34;.pickle&#34;,&#34;rb&#34;)
                inst = pickle.load(f)
                f.close()
                return inst
            elif os.path.isfile(folder+filename+&#34;.txt&#34;):
                data, info = wormdm.signal.from_file(folder,filename)
                try:
                    data.shape[1]
                except:
                    data = np.copy(np.reshape(data,(data.shape[0],1)))
            
                inst = cls(data,info,filename,*args,**kwargs)
                return inst
            else:
                print(folder+filename+&#34; is not present.&#34;)
                quit()
                
    @classmethod
    def from_signal_and_reference(cls, folder, uncorr_signal_fname, reference_fname, method=0.0, strides = [], stride_names = [], stride_skip = []):
        
        # If the filename does not have any extension assign one. If both pickle
        # file exist, then load the pickles if the pickle file is newer than
        # the txt, otherwise load the raw txt.
        if len(uncorr_signal_fname.split(&#34;.&#34;)) == 1:
            if os.path.isfile(folder+uncorr_signal_fname+&#34;.pickle&#34;) and os.path.isfile(folder+reference_fname+&#34;.pickle&#34;):
                if os.path.getmtime(folder+uncorr_signal_fname+&#34;.pickle&#34;) &gt; os.path.getmtime(folder+uncorr_signal_fname+&#34;.txt&#34;):
                    uncorr_signal_fname += &#34;.pickle&#34;
                    reference_fname += &#34;.pickle&#34;
                else:
                    uncorr_signal_fname += &#34;.txt&#34;
                    reference_fname += &#34;.txt&#34;
            else:
                uncorr_signal_fname += &#34;.txt&#34;
                reference_fname += &#34;.txt&#34;
        
        # Extract description and extensions from the filenames
        uncorr_signal_ext = uncorr_signal_fname.split(&#34;.&#34;)[-1]
        uncorr_signal_descr = uncorr_signal_fname.split(&#34;.&#34;)[:-1]
        reference_ext = reference_fname.split(&#34;.&#34;)[-1]
        reference_descr = reference_fname.split(&#34;.&#34;)[:-1]
        
        # If the two extensions are different, quit.
        if uncorr_signal_ext != reference_ext:
            print(&#34;Provide the source of the uncorrected signal and reference from the same file format.&#34;)
            quit()
        
        # If loading from the raw txt files, preprocess. If loading from the 
        # pickles, do not preprocess.
        if uncorr_signal_ext == &#34;txt&#34;:
            uncorr_signal = cls.from_file(folder, uncorr_signal_fname, nan_interp=True, smooth=False, photobl_calc=True, photobl_appl=False, strides = [], stride_names = [], stride_skip = [])
            reference = cls.from_file(folder, reference_fname, nan_interp=True, smooth=False, photobl_calc=True, photobl_appl=False, corr_inst_photobl=True, strides = [], stride_names = [], stride_skip = [])
            
            # Save the preprocessed files.
            uncorr_signal.to_file(folder,&#34;.&#34;.join([uncorr_signal_fname.split(&#34;.&#34;)[0],&#34;pickle&#34;]) )
            reference.to_file(folder,&#34;.&#34;.join([reference_fname.split(&#34;.&#34;)[0],&#34;pickle&#34;]))
            
        elif uncorr_signal_ext == &#34;pickle&#34;:
            uncorr_signal = cls.from_file(folder, uncorr_signal_fname, preprocess=False)
            reference = cls.from_file(folder, reference_fname, preprocess=False)
            if os.path.isfile(folder+cls.filename):
                signal = cls.from_file(folder,cls.filename)
                if signal.info[&#34;correction_method&#34;] == method: 
                    print(&#34;Using pickled signal.&#34;)
                    return signal
        
        # Merge the infos from the source Signal objects
        info = reference.info.copy()
        info[&#34;uncorr_signal&#34;] = uncorr_signal.info
        info[&#34;reference&#34;] = reference.info 
        info[&#34;correction_method&#34;] = method
        
        # Compute the corrected signal based on one of the methods available.
        signal_d = np.zeros_like(reference.data)
        if method == 0.0:
            # Standard ratiometric
            X = np.arange(uncorr_signal.data.shape[0])
            for k in np.arange(uncorr_signal.data.shape[1]):
                unc_sig_pb = uncorr_signal._double_exp(X,uncorr_signal.photobl_p[k])
                ref_pb = reference._double_exp(X,reference.photobl_p[k])
                #signal_d[:,k] = (uncorr_signal.data[:,k])/(reference.data[:,k])*(ref_pb*reference.maxY[k])/(unc_sig_pb*uncorr_signal.maxY[k])
                # Removing the normalizations, I want it to have the same 
                # amplitude as the raw GCaMP fluorescence, so that it&#39;s kind of 
                # not cell-specific.
                signal_d[:,k] = (uncorr_signal.data[:,k])/(reference.data[:,k])*(ref_pb*reference.maxY[k])/(unc_sig_pb)
        elif method==1.5:
            # Derivative-based, version 1.5
            X = np.arange(uncorr_signal.data.shape[0])
            for k in np.arange(uncorr_signal.data.shape[1]):
                P = reference.photobl_p
                Y = cls._double_exp(X,P[k])
                prop = (Y[1:]-P[k,-1])/(Y[:-1]-P[k,-1])
                oneplusdelta = (reference[1:,k]/reference[:-1,k])*prop
                oneplusd = uncorr_signal[1:,k]/uncorr_signal[:-1,k]/oneplusdelta
                signal_d[0,k] = uncorr_signal[0,k]
                for i in np.arange(uncorr_signal.data.shape[0]-1):
                    signal_d[i+1,k] = signal_d[i,k]*oneplusd[i]
        elif method == 1.6:
            # Derivative-based, verions 1.6
            X = np.arange(uncorr_signal.data.shape[0])
            for k in np.arange(uncorr_signal.data.shape[1]):
                P = reference.photobl_p
                Y = cls._double_exp(X,P[k])
                prop = (Y[1:]-P[k,-1])/(Y[:-1]-P[k,-1])
                whatRshouldbe = (reference[:-1,k]-P[k,-1])*prop+P[k,-1]
                oneplusdelta = reference[1:,k]/whatRshouldbe
                oneplusd = (uncorr_signal[1:,k]+100)/(uncorr_signal[:-1,k]+100)/oneplusdelta
                signal_d[0,k] = uncorr_signal[0,k]+100
                for i in np.arange(uncorr_signal.data.shape[0]-1):
                    signal_d[i+1,k] = signal_d[i,k]*oneplusd[i]
        elif method == 2.0:
            # ICA
            X = np.arange(uncorr_signal.data.shape[0])
            rlocstd = reference.get_loc_std(8)
            unclocstd = uncorr_signal.get_loc_std()
            trasformer = FastICA(n_components=2, random_state=0)
            for k in np.arange(uncorr_signal.data.shape[1]):
                unc_sig_pb = uncorr_signal._double_exp(X,uncorr_signal.photobl_p[k])
                ref_pb = reference._double_exp(X,reference.photobl_p[k])
                mixed = np.array([uncorr_signal.data[:,k]/unc_sig_pb/unclocstd[k],reference.data[:,k]/ref_pb/rlocstd[k]]).T
                signal_d[:,k] = mixed[:,0]
        
        
        if method == 1.6: photobl_calc = photobl_appl = True
        else: photobl_calc = photobl_appl = False
        #photobl_calc = photobl_appl = False
        
        # Create the Signal object with the corrected signal.
        signal = cls(signal_d, info, description=&#34;signal&#34;, strides=strides, stride_names=stride_names, stride_skip=stride_skip, photobl_calc=photobl_calc, photobl_appl=photobl_appl)
            
        # Transfer logbooks from the original Signal objects
        signal.logbook += &#34;Uncorrected signal log:\n&#34;+&#34;\t&#34;+&#34;\n\t&#34;.join(uncorr_signal.logbook.split(&#34;\n&#34;))[:-2]+&#34;\n&#34;
        signal.logbook += &#34;Reference log:\n&#34;+&#34;\t&#34;+&#34;\n\t&#34;.join(reference.logbook.split(&#34;\n&#34;))[:-2]+&#34;\n&#34;
        
        # Transfer nanmask
        signal.nan_mask = np.logical_or(reference.nan_mask,signal.nan_mask)
            
        signal.to_file(folder,cls.filename)
            
        return signal
        
    def to_file(self,folder,filename):
        if filename.split(&#34;.&#34;)[-1] != &#34;pickle&#34;:
            filename += &#34;.pickle&#34;
        pickle_file = open(folder+filename,&#34;wb&#34;)
        pickle.dump(self,pickle_file)
        pickle_file.close()
        
    def log(self, s = None, print_to_terminal = True):
        &#39;&#39;&#39;Write an entry in the internal log and, if requested, print the same
        entry to terminal. In the log, the entry will start with the 
        current time.
        
        Parameters
        ----------
        s: string
            Text of the entry.
        print_to_terminal: boolean
            If True, the entry will also be printed to terminal. Default: True.

        Returns
        -------
        None
        &#39;&#39;&#39;
        if s is not None:
            now = datetime.now()
            dt = now.strftime(&#34;%Y-%m-%d %H:%M:%S: &#34;)
            self.logbook += (dt+s+&#34;\n&#34;)
            if print_to_terminal:
                print(&#34;Signal &#34;+self.description+&#34;: &#34;+s)
    
    ##### Pre-processing Functions #####
    
    def interpolate_nans(self):
        &#39;&#39;&#39;Replace nans with an interpolated value.&#39;&#39;&#39;
        
        self.log(&#34;Replacing nans with the interpolated value.&#34;,False)
        interpolated = np.copy(self.data)
        
        for i in np.arange(self.data.shape[1]):
            # nans: location of nans
            # x: function that finds the non-zero entries
            nans, x = self.nan_mask[:,i], lambda z: z.nonzero()[0]
            try:
                interpolated[nans,i] = np.interp(x(nans), x(~nans), self.data[~nans,i])
            except:
                pass
        
        return interpolated
    
    def smooth(self, n):
        &#39;&#39;&#39;Smooth the signal with a rectangular filter.
        
        Parameters
        ----------
        n: int
            Width of the rectangular filter.        
        &#39;&#39;&#39;
        self.log(&#34;Smoothing signal with a window of &#34;+str(n)+&#34; points.&#34;,False)
        
        sm = np.ones(n)/n
        smoothed = np.copy(self.data)    
        
        for i in np.arange(self.data.shape[1]):
            smoothed[:,i] = np.convolve(self.data[:,i],sm,mode=&#34;same&#34;)
        
        return smoothed
        
    @staticmethod    
    def _double_exp(X,P):
        &#39;&#39;&#39;Photobleaching correction target function&#39;&#39;&#39;
        Y = P[0]*np.exp(-X*np.abs(P[1])) + P[2]*np.exp(-X*np.abs(P[3])) + np.abs(P[-1])
        return Y
        
    @staticmethod    
    def _error(P,f,X,Y):
        &#39;&#39;&#39;Photobleaching correction error function&#39;&#39;&#39;
        e = np.sum(np.power(f(X,P)-Y,2))
        return e
            
    def calc_photobl(self, j=None):
        data_corr = np.copy(self.data)
        X = np.arange(self.data.shape[0])
        self.log(&#34;Calculating photobleaching correction, but not applying it.&#34;,True)
        
        if j is None:
            iterate_over = np.arange(self.data.shape[1])
        else:
            try: len(j)
            except: j = [j]
            iterate_over = j 
        
        for k in iterate_over:
            print(&#34;\t&#34;+str(np.around(float(k)/self.data.shape[1],4))+&#34; done.   &#34;,end=&#34;&#34;)
            try:
                self.maxY[k] = np.max(data_corr[:,k])
                Y = data_corr[:,k]/self.maxY[k]
                mask = np.ones_like(Y,dtype=np.bool)
                P = np.array([1.,0.006,1.,0.001,0.2])
                
                it = 0
                while True and it&lt;100:
                    R = minimize(self._error,P,args=(self._double_exp,X[mask],Y[mask]))
                    if np.sum(np.absolute((P-R.x)/P)) &lt; 1e-2: break
                    P = R.x
                    
                    std = np.std(self._double_exp(X[mask],P)-Y[mask])
                    mask[:] = np.absolute(self._double_exp(X,P)-Y) &lt; 2.*std
                    it += 1
                
                self.photobl_p[k] = P    
                print(&#34;\r&#34;,end=&#34;&#34;)
            except Exception as e:
                self.log(&#34;Problems with trace &#34;+str(k)+&#34;: &#34;+str(e))

    def appl_photobl(self, j=None):
        &#39;&#39;&#39;Apply the precomputed photobleaching correction.
        
        Parameters
        ----------
        j: int (optional)
            Neuron to which to apply the correction. If None, the correction 
            will be applied to all the neurons. Default: None.
        &#39;&#39;&#39; 
        
        self.log(&#34;Applying the photobleaching correction.&#34;,True)
        X = np.arange(self.data.shape[0])
        if j is None:
            iterate_over = np.arange(self.data.shape[1])
        else:
            try: len(j)
            except: j = [j]
            iterate_over = j
            
        for k in iterate_over:
            data_photobleach_fit = self._double_exp(X,self.photobl_p[k])*self.maxY[k]
            self.data[:,k] /= (1.+data_photobleach_fit)
            
    #def get_photobl_fit(self, X, k=None):
    
    def corr_inst_photobl(self, j=None, poly_width=111, photobl_duration=3, min_distance=30):

        if j is None:
            iterate_over = np.arange(self.data.shape[1])
        else:
            try: len(j)
            except: j = [j]
            iterate_over = j
            
        # Calculate derivative (and diff, will be useful later)
        deriv = np.zeros((self.data.shape[0],len(iterate_over)))
        diff = np.zeros((self.data.shape[0],len(iterate_over)))
        derker = -sg.get_1D_filter(poly_width,3,1)        
        for i in np.arange(len(iterate_over)):
            k = iterate_over[i]
            deriv[:,i] = np.convolve(derker,self.data[:,k],mode=&#34;same&#34;)
            diff[:-1,i] = np.diff(self.data[:,k])
            
        # Find where the derivative departs from normal behavior    
        medderiv = np.median(deriv[poly_width:-poly_width],axis=0)
        stdderiv = np.std(deriv[poly_width:-poly_width],axis=0)
        
        for i in np.arange(len(iterate_over)):
            k = iterate_over[i]
            i_pb = np.where(deriv[poly_width:-poly_width,i]&lt;medderiv[i]-3*stdderiv[i])[0]+poly_width
            
            prev_jump_pos = -100*min_distance
            if len(i_pb)&gt;0:
                # Find contiguous regions where the derivative is too negative
                splt = np.where(np.diff(i_pb)&gt;1)[0]+1
                splt = np.append(0,splt)
                splt = np.append(splt,-1)
                for q in np.arange(len(splt)-1):
                    # Find the &#34;real&#34; center of the jump 
                    idx0 = i_pb[splt[q]]
                    idx1 = i_pb[splt[q+1]]
                    if idx1&gt;(idx0+1):
                        #jump_pos_poly = np.argmin(deriv[idx0:idx1,i])+idx0
                        jump_pos = np.argmin(diff[idx0:idx1,i])+idx0
                    else:
                        jump_pos = idx0
                    
                    # Sometimes a region that should be contiguous is split.
                    # If two detected jumps are too close they are likely
                    # originating from this situation, so don&#39;t double count
                    # them.
                    if jump_pos&lt;(prev_jump_pos+min_distance): continue
                    prev_jump_pos = jump_pos
                    
                    # Calculate the amplitude of the jump
                    jump = np.sum(deriv[jump_pos-poly_width//2:jump_pos+poly_width//2,i])
                    
                    # Calculate the factor by which the post-jump data needs to 
                    # be multiplied to be corrected
                    # Pre-jump value: could be something more fancy since you&#39;re
                    # doing polynomial interpolation
                    pre = np.median(self.data[jump_pos-10:jump_pos,k])
                    mult = pre/(pre+jump)
                    
                    self.data[jump_pos+photobl_duration:,k] *= mult
                
        
    
    ##### Additional Capabilities #####
    
    def trim(self,stride_name, adjust = None):
        &#39;&#39;&#39;If the signal is an irregular array, trim it to make the regularize
        the stride along the irregular axis.
        
        Parameters
        ----------
        stride_name: string
            Name of the stride along which to trim.
        adjust: int
            Number of points to average to subtract the background.
            
        Returns
        -------
        trimmed: irregular array
            Irregular array that has now effectively a regular stride. 
            trimmed.data can now be copied and reshaped into a multidimensional
            numpy array.        
        &#39;&#39;&#39;
        
        try:
            start = self.data.firstIndex[stride_name];
            strideLength = np.diff(start);
        except:
            print(&#39;Trim unsuccesful, signal has no strides by the name &#34;&#39; + stride_name + &#39;&#34;.&#39;)
            quit()
        
        mask = np.ones(strideLength.shape, dtype = bool);
        mask[self.which_skip[stride_name]] = False;
        min_len = np.min(strideLength[mask])
        
        temp_data = np.ones((1,self.data.shape[1]))
        temp_nan = np.ones((1,self.data.shape[1]))
        
        for stPt in start[np.append(mask,False)]:
            if adjust == None: adj = 0;
            else: adj = np.mean(self.data[stPt:stPt+adjust],axis=0);
            temp_data = np.vstack((temp_data,self.data[stPt:stPt+min_len]-adj));
            temp_nan = np.vstack((temp_nan,self.nan_mask[stPt:stPt+min_len]));
        temp_data = np.copy(temp_data[1:])
        temp_nan = np.copy(temp_nan[1:])
        
        temp_strides = (np.ones_like(strideLength[mask])*min_len)
        #temp_strides = (np.ones_like(strideLength)*min_len)
        # print(&#39;trimmed strides&#39;,temp_strides)
        
        trimmed = self.copy()
        trimmed.data = irrarray(temp_data, [temp_strides], strideNames=[stride_name])
        trimmed.nan_mask = irrarray(temp_nan, [temp_strides], strideNames=[stride_name])
        trimmed.which_skip = dict({stride_name : []});
        
        return trimmed
        
    def average(self,stride_name, adjust = None):
        &#39;&#39;&#39;Average the signal over an irregular stride. The function first
        obtains the trimmed version of the array along that stride, subtracts
        the background, and averages across the events.
        
        Parameters
        ----------
        stride_name: str
            Name of the irregular stride.
        adjust: int
            Number of points to average for the background subtraction.
            
        Returns
        -------
        avg: numpy array
            Array containing the average over the specified stride.
        
        &#39;&#39;&#39;
        
        # adjust tells you how many points to average as a baseline to subtract out
        try:
            trimmed = self.trim(stride_name, adjust = adjust);
        except:
            print(&#39;Average unsuccessful, signal has no strides by the name &#34;&#39; + stride_name + &#39;&#34;.&#39;)
            quit()
        length = trimmed.data.firstIndex[stride_name][1];
        numStrides = trimmed.data.firstIndex[stride_name].size-1
        temp = np.reshape(trimmed.data,(numStrides,length,trimmed.data.shape[1])) 
        avg = np.mean(temp,axis = 0)
        return avg
        
    def get_loc_std(self,window=8):
        loc_std = np.zeros(self.data.shape[1])
        for j in np.arange(self.data.shape[1]):
            loc_std[j] = np.sqrt(np.median(np.var(self.rolling_window(self.data[:,j], window), axis=-1)))
            
        return loc_std
    
    ##### Underbelly Functions #####
    
    def copy(self):
        return deepcopy(self)
        
    def __getitem__(self, i):
        &#39;&#39;&#39;Allow for direct indexing of the class to access the data.&#39;&#39;&#39;
        return self.data.__getitem__(i)
        
    def __setitem__(self, i, value):
        &#39;&#39;&#39;Allow for direct indexing of the class to write in the data.&#39;&#39;&#39;
        self.data.__setitem__(i,value)
        
    def __call__(self, *args, **kwargs):
        &#39;&#39;&#39;Upon call, use the __call__ method of the data irrarray.&#39;&#39;&#39;
        return self.data.__call__(*args, **kwargs)
        
        
    @staticmethod
    def rolling_window(a, window):
        pad = np.ones(len(a.shape), dtype=np.int32)
        pad[-1] = window-1
        pad = list(zip(pad, np.zeros(len(a.shape), dtype=np.int32)))
        a = np.pad(a, pad,mode=&#39;reflect&#39;)
        shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
        strides = a.strides + (a.strides[-1],)
        return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="wormdatamodel.signal.signal.Signal"><code class="flex name class">
<span>class <span class="ident">Signal</span></span>
<span>(</span><span>data, info, description=None, strides=[], stride_names=[], stride_skip=[[0]], preprocess=None, nan_interp=True, smooth=False, smooth_n=4, photobl_calc=False, photobl_appl=False, corr_inst_photobl=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Class representing signal extracted from recording. It supports irregular
striding of the signal, useful for recordings with associated events, like
optogenetics stimulations. The metadata about the irregular strides can be
obtained via the recording.get_events() method.</p>
<p>The class provides some preprocessing functionalities, like
nan-interpolation, smoothing, and in the future will provide photobleaching
correction, with the goal of abstracting all this away from the scripts
analysing the signal.
</p>
<p>Constructor for the class. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>2D array containing the data. The outermost axis has to be the one
that gets strided irregularly.</dd>
<dt><strong><code>info</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary containing the metadata about how the signal has been
extracted from the frames.</dd>
<dt><strong><code>strides</code></strong> :&ensp;<code>list</code> of <code>numpy arrays (optional)</code></dt>
<dd>Usually, the ones returned from recording.get_events().
See documentation for the irregular array. Default: empty.</dd>
<dt><strong><code>stride_names</code></strong> :&ensp;<code>list</code> of <code>strings (optional)</code></dt>
<dd>See documentation for the irregular array. Default: empty.</dd>
<dt><strong><code>stride_skip</code></strong> :&ensp;<code>list</code> of <code>integers (optional)</code></dt>
<dd>Number of strides to skip at the beginning. Default: empty.</dd>
<dt><strong><code>preprocess</code></strong> :&ensp;<code>bool</code></dt>
<dd>Apply the all the preprocessing to the signal. It does not control
the correction of instantaneous photobleaching. Default: False.</dd>
<dt>nan_interp: bool.</dt>
<dt>Interpolate nans. Default: True.</dt>
<dt><strong><code>smooth</code></strong> :&ensp;<code>bool</code></dt>
<dd>Smooth with a box of size smooth_n. Default: False.</dd>
<dt><strong><code>smooth_n</code></strong> :&ensp;<code>int</code></dt>
<dd>Size of the smoothing box. Default: 4.</dd>
<dt><strong><code>photobl_calc</code></strong> :&ensp;<code>bool</code></dt>
<dd>Calculate the photobleaching correction. Set this to True instead of
photobl_appl if you are using the photobleaching correction for one
of the ratiometric methods. Default: False.</dd>
<dt><strong><code>photobl_appl</code></strong> :&ensp;<code>bool</code></dt>
<dd>Apply the photobleaching correction. If True, the photobleaching
correction will be calculated. Default: False.</dd>
<dt><strong><code>corr_inst_photobl</code></strong> :&ensp;<code>bool</code></dt>
<dd>Detect and correct instantaneous photobleaching. Use only for the
red signal. Default: False.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Signal:
    &#39;&#39;&#39;Class representing signal extracted from recording. It supports irregular
    striding of the signal, useful for recordings with associated events, like
    optogenetics stimulations. The metadata about the irregular strides can be 
    obtained via the recording.get_events() method.
    
    The class provides some preprocessing functionalities, like 
    nan-interpolation, smoothing, and in the future will provide photobleaching
    correction, with the goal of abstracting all this away from the scripts
    analysing the signal.    
    &#39;&#39;&#39;

    nan_mask = np.zeros(1) # where nans
    data = np.empty((0,0)); # data array; either ndarray or irrarray
    info = [];
    which_skip = dict(zip([],[])); # which strides should be ignored
    
    maxY = np.empty((0))
    photobl_p = np.empty((0,0))
    photobl_n_params = 5
    
    logbook = &#34;&#34;
    
    description = &#34;_created from data_&#34;
    filename = &#34;signal.pickle&#34;
    
    def __init__(self, data, info, description = None, 
                 strides = [], stride_names = [], stride_skip = [[0]], 
                 preprocess = None, nan_interp = True, 
                 smooth = False, smooth_n=4, 
                 photobl_calc = False, photobl_appl = False,
                 corr_inst_photobl = False):
        &#39;&#39;&#39;Constructor for the class. 
        
        Parameters
        ----------
        data: numpy array
            2D array containing the data. The outermost axis has to be the one
            that gets strided irregularly.
        info: dict
            Dictionary containing the metadata about how the signal has been
            extracted from the frames.
        strides: list of numpy arrays (optional)
            Usually, the ones returned from recording.get_events().
            See documentation for the irregular array. Default: empty.
        stride_names: list of strings (optional)
            See documentation for the irregular array. Default: empty.
        stride_skip: list of integers (optional)
            Number of strides to skip at the beginning. Default: empty.
        preprocess: bool
            Apply the all the preprocessing to the signal. It does not control 
            the correction of instantaneous photobleaching. Default: False.     
        nan_interp: bool.
            Interpolate nans. Default: True.
        smooth: bool
            Smooth with a box of size smooth_n. Default: False.
        smooth_n: int
            Size of the smoothing box. Default: 4.
        photobl_calc: bool
            Calculate the photobleaching correction. Set this to True instead of
            photobl_appl if you are using the photobleaching correction for one
            of the ratiometric methods. Default: False.
        photobl_appl: bool
            Apply the photobleaching correction. If True, the photobleaching 
            correction will be calculated. Default: False.
        corr_inst_photobl: bool
            Detect and correct instantaneous photobleaching. Use only for the
            red signal. Default: False.
        &#39;&#39;&#39;

        self.data = data;
        self.info = info;
        if description is not None: self.description = description
        
        # Preprocessing
        self.nan_mask = np.isnan(self.data)
        self.maxY = np.zeros(self.data.shape[1])
        self.photobl_p = np.zeros((self.data.shape[1],5))
        
        self.smooth_n = smooth_n; # smoothing parameter
        if preprocess is not None:
            if preprocess:
                nan_interp = True
                smooth = True
                photobl_calc = True
                photobl_appl = True
            elif not preprocess:
                nan_interp = False
                smooth = False
                photobl_calc = False
                photobl_appl = False
        if photobl_appl: photobl_calc = True
        
        if nan_interp: self.data = self.interpolate_nans();
        if corr_inst_photobl: self.corr_inst_photobl();
        if photobl_calc: self.calc_photobl()
        if photobl_appl: self.appl_photobl()
        if smooth: self.data = self.smooth(smooth_n);
            
        
        # strides option allows you to construct an irregular array
        self.which_skip = dict(zip(stride_names,stride_skip))
        if len(strides) &gt; 0:
            
            # make sure that stride_names matches in size with the number stride arrays provided
            if len(stride_names) &gt; len(strides):
                warnings.warn(&#39;More stride names specified than stride arrays. Unused have been cut.&#39;);
                stride_names = stride_names[0:len(strides)]
            elif len(stride_names) &lt; len(strides):
                warnings.warn(&#39;Fewer stride names specified than stride arrays. &#39; + 
                &#39;Additional strides have been set to the default (thing_0, thing_1, ...).&#39;);
                for i in np.arange(len(strides) - len(stride_names)):
                    stride_names += [&#39;thing_&#39; + str(i)]
            
            data_uncut = np.copy(self.data)
            self.data = irrarray(data_uncut, strides, strideNames=stride_names)
            
            mask_uncut = np.copy(self.nan_mask)
            self.nan_mask = irrarray(mask_uncut, strides, strideNames=stride_names)
    
    
    @classmethod
    def from_file(cls,folder,filename,*args,**kwargs):
        &#39;&#39;&#39;Creates an instance of the class loading the data from file. If 
        filename ends with &#34;.txt&#34; the Signal object will be created from the 
        raw data. If the filename ends with &#34;.pickle&#34;, the function will load
        the data from the pickled file. If the filename does not end with either
        extension, the data will be loaded from the pickled file filename.pickle
        if present, otherwise from the raw filename.txt. 
        
        Parameters
        ----------
        folder: str
            Folder containing the file.
        filename: str
            Name of the file containing the signal array.
        *args, **kwargs
            Any other parameter to be passed to the constructor.
        &#39;&#39;&#39;
        
        if filename.split(&#34;.&#34;)[-1] == &#34;txt&#34;: 
            # read in data; rows = time, columns = neuron
            data, info = wormdm.signal.from_file(folder,filename)
            # adjusting the shape so that even if only one neuron, still has &#34;columns&#34;
            try:
                data.shape[1]
            except:
                data = np.copy(np.reshape(data,(data.shape[0],1)))
            
            inst = cls(data,info,&#34;.&#34;.join(filename.split(&#34;.&#34;)[:-1]),*args,**kwargs)
            return inst
            
        elif filename.split(&#34;.&#34;)[-1] == &#34;pickle&#34;:
            f = open(folder+filename,&#34;rb&#34;)
            inst = pickle.load(f)
            f.close()
            return inst
        else:
            if os.path.isfile(folder+filename+&#34;.pickle&#34;):
                f = open(folder+filename+&#34;.pickle&#34;,&#34;rb&#34;)
                inst = pickle.load(f)
                f.close()
                return inst
            elif os.path.isfile(folder+filename+&#34;.txt&#34;):
                data, info = wormdm.signal.from_file(folder,filename)
                try:
                    data.shape[1]
                except:
                    data = np.copy(np.reshape(data,(data.shape[0],1)))
            
                inst = cls(data,info,filename,*args,**kwargs)
                return inst
            else:
                print(folder+filename+&#34; is not present.&#34;)
                quit()
                
    @classmethod
    def from_signal_and_reference(cls, folder, uncorr_signal_fname, reference_fname, method=0.0, strides = [], stride_names = [], stride_skip = []):
        
        # If the filename does not have any extension assign one. If both pickle
        # file exist, then load the pickles if the pickle file is newer than
        # the txt, otherwise load the raw txt.
        if len(uncorr_signal_fname.split(&#34;.&#34;)) == 1:
            if os.path.isfile(folder+uncorr_signal_fname+&#34;.pickle&#34;) and os.path.isfile(folder+reference_fname+&#34;.pickle&#34;):
                if os.path.getmtime(folder+uncorr_signal_fname+&#34;.pickle&#34;) &gt; os.path.getmtime(folder+uncorr_signal_fname+&#34;.txt&#34;):
                    uncorr_signal_fname += &#34;.pickle&#34;
                    reference_fname += &#34;.pickle&#34;
                else:
                    uncorr_signal_fname += &#34;.txt&#34;
                    reference_fname += &#34;.txt&#34;
            else:
                uncorr_signal_fname += &#34;.txt&#34;
                reference_fname += &#34;.txt&#34;
        
        # Extract description and extensions from the filenames
        uncorr_signal_ext = uncorr_signal_fname.split(&#34;.&#34;)[-1]
        uncorr_signal_descr = uncorr_signal_fname.split(&#34;.&#34;)[:-1]
        reference_ext = reference_fname.split(&#34;.&#34;)[-1]
        reference_descr = reference_fname.split(&#34;.&#34;)[:-1]
        
        # If the two extensions are different, quit.
        if uncorr_signal_ext != reference_ext:
            print(&#34;Provide the source of the uncorrected signal and reference from the same file format.&#34;)
            quit()
        
        # If loading from the raw txt files, preprocess. If loading from the 
        # pickles, do not preprocess.
        if uncorr_signal_ext == &#34;txt&#34;:
            uncorr_signal = cls.from_file(folder, uncorr_signal_fname, nan_interp=True, smooth=False, photobl_calc=True, photobl_appl=False, strides = [], stride_names = [], stride_skip = [])
            reference = cls.from_file(folder, reference_fname, nan_interp=True, smooth=False, photobl_calc=True, photobl_appl=False, corr_inst_photobl=True, strides = [], stride_names = [], stride_skip = [])
            
            # Save the preprocessed files.
            uncorr_signal.to_file(folder,&#34;.&#34;.join([uncorr_signal_fname.split(&#34;.&#34;)[0],&#34;pickle&#34;]) )
            reference.to_file(folder,&#34;.&#34;.join([reference_fname.split(&#34;.&#34;)[0],&#34;pickle&#34;]))
            
        elif uncorr_signal_ext == &#34;pickle&#34;:
            uncorr_signal = cls.from_file(folder, uncorr_signal_fname, preprocess=False)
            reference = cls.from_file(folder, reference_fname, preprocess=False)
            if os.path.isfile(folder+cls.filename):
                signal = cls.from_file(folder,cls.filename)
                if signal.info[&#34;correction_method&#34;] == method: 
                    print(&#34;Using pickled signal.&#34;)
                    return signal
        
        # Merge the infos from the source Signal objects
        info = reference.info.copy()
        info[&#34;uncorr_signal&#34;] = uncorr_signal.info
        info[&#34;reference&#34;] = reference.info 
        info[&#34;correction_method&#34;] = method
        
        # Compute the corrected signal based on one of the methods available.
        signal_d = np.zeros_like(reference.data)
        if method == 0.0:
            # Standard ratiometric
            X = np.arange(uncorr_signal.data.shape[0])
            for k in np.arange(uncorr_signal.data.shape[1]):
                unc_sig_pb = uncorr_signal._double_exp(X,uncorr_signal.photobl_p[k])
                ref_pb = reference._double_exp(X,reference.photobl_p[k])
                #signal_d[:,k] = (uncorr_signal.data[:,k])/(reference.data[:,k])*(ref_pb*reference.maxY[k])/(unc_sig_pb*uncorr_signal.maxY[k])
                # Removing the normalizations, I want it to have the same 
                # amplitude as the raw GCaMP fluorescence, so that it&#39;s kind of 
                # not cell-specific.
                signal_d[:,k] = (uncorr_signal.data[:,k])/(reference.data[:,k])*(ref_pb*reference.maxY[k])/(unc_sig_pb)
        elif method==1.5:
            # Derivative-based, version 1.5
            X = np.arange(uncorr_signal.data.shape[0])
            for k in np.arange(uncorr_signal.data.shape[1]):
                P = reference.photobl_p
                Y = cls._double_exp(X,P[k])
                prop = (Y[1:]-P[k,-1])/(Y[:-1]-P[k,-1])
                oneplusdelta = (reference[1:,k]/reference[:-1,k])*prop
                oneplusd = uncorr_signal[1:,k]/uncorr_signal[:-1,k]/oneplusdelta
                signal_d[0,k] = uncorr_signal[0,k]
                for i in np.arange(uncorr_signal.data.shape[0]-1):
                    signal_d[i+1,k] = signal_d[i,k]*oneplusd[i]
        elif method == 1.6:
            # Derivative-based, verions 1.6
            X = np.arange(uncorr_signal.data.shape[0])
            for k in np.arange(uncorr_signal.data.shape[1]):
                P = reference.photobl_p
                Y = cls._double_exp(X,P[k])
                prop = (Y[1:]-P[k,-1])/(Y[:-1]-P[k,-1])
                whatRshouldbe = (reference[:-1,k]-P[k,-1])*prop+P[k,-1]
                oneplusdelta = reference[1:,k]/whatRshouldbe
                oneplusd = (uncorr_signal[1:,k]+100)/(uncorr_signal[:-1,k]+100)/oneplusdelta
                signal_d[0,k] = uncorr_signal[0,k]+100
                for i in np.arange(uncorr_signal.data.shape[0]-1):
                    signal_d[i+1,k] = signal_d[i,k]*oneplusd[i]
        elif method == 2.0:
            # ICA
            X = np.arange(uncorr_signal.data.shape[0])
            rlocstd = reference.get_loc_std(8)
            unclocstd = uncorr_signal.get_loc_std()
            trasformer = FastICA(n_components=2, random_state=0)
            for k in np.arange(uncorr_signal.data.shape[1]):
                unc_sig_pb = uncorr_signal._double_exp(X,uncorr_signal.photobl_p[k])
                ref_pb = reference._double_exp(X,reference.photobl_p[k])
                mixed = np.array([uncorr_signal.data[:,k]/unc_sig_pb/unclocstd[k],reference.data[:,k]/ref_pb/rlocstd[k]]).T
                signal_d[:,k] = mixed[:,0]
        
        
        if method == 1.6: photobl_calc = photobl_appl = True
        else: photobl_calc = photobl_appl = False
        #photobl_calc = photobl_appl = False
        
        # Create the Signal object with the corrected signal.
        signal = cls(signal_d, info, description=&#34;signal&#34;, strides=strides, stride_names=stride_names, stride_skip=stride_skip, photobl_calc=photobl_calc, photobl_appl=photobl_appl)
            
        # Transfer logbooks from the original Signal objects
        signal.logbook += &#34;Uncorrected signal log:\n&#34;+&#34;\t&#34;+&#34;\n\t&#34;.join(uncorr_signal.logbook.split(&#34;\n&#34;))[:-2]+&#34;\n&#34;
        signal.logbook += &#34;Reference log:\n&#34;+&#34;\t&#34;+&#34;\n\t&#34;.join(reference.logbook.split(&#34;\n&#34;))[:-2]+&#34;\n&#34;
        
        # Transfer nanmask
        signal.nan_mask = np.logical_or(reference.nan_mask,signal.nan_mask)
            
        signal.to_file(folder,cls.filename)
            
        return signal
        
    def to_file(self,folder,filename):
        if filename.split(&#34;.&#34;)[-1] != &#34;pickle&#34;:
            filename += &#34;.pickle&#34;
        pickle_file = open(folder+filename,&#34;wb&#34;)
        pickle.dump(self,pickle_file)
        pickle_file.close()
        
    def log(self, s = None, print_to_terminal = True):
        &#39;&#39;&#39;Write an entry in the internal log and, if requested, print the same
        entry to terminal. In the log, the entry will start with the 
        current time.
        
        Parameters
        ----------
        s: string
            Text of the entry.
        print_to_terminal: boolean
            If True, the entry will also be printed to terminal. Default: True.

        Returns
        -------
        None
        &#39;&#39;&#39;
        if s is not None:
            now = datetime.now()
            dt = now.strftime(&#34;%Y-%m-%d %H:%M:%S: &#34;)
            self.logbook += (dt+s+&#34;\n&#34;)
            if print_to_terminal:
                print(&#34;Signal &#34;+self.description+&#34;: &#34;+s)
    
    ##### Pre-processing Functions #####
    
    def interpolate_nans(self):
        &#39;&#39;&#39;Replace nans with an interpolated value.&#39;&#39;&#39;
        
        self.log(&#34;Replacing nans with the interpolated value.&#34;,False)
        interpolated = np.copy(self.data)
        
        for i in np.arange(self.data.shape[1]):
            # nans: location of nans
            # x: function that finds the non-zero entries
            nans, x = self.nan_mask[:,i], lambda z: z.nonzero()[0]
            try:
                interpolated[nans,i] = np.interp(x(nans), x(~nans), self.data[~nans,i])
            except:
                pass
        
        return interpolated
    
    def smooth(self, n):
        &#39;&#39;&#39;Smooth the signal with a rectangular filter.
        
        Parameters
        ----------
        n: int
            Width of the rectangular filter.        
        &#39;&#39;&#39;
        self.log(&#34;Smoothing signal with a window of &#34;+str(n)+&#34; points.&#34;,False)
        
        sm = np.ones(n)/n
        smoothed = np.copy(self.data)    
        
        for i in np.arange(self.data.shape[1]):
            smoothed[:,i] = np.convolve(self.data[:,i],sm,mode=&#34;same&#34;)
        
        return smoothed
        
    @staticmethod    
    def _double_exp(X,P):
        &#39;&#39;&#39;Photobleaching correction target function&#39;&#39;&#39;
        Y = P[0]*np.exp(-X*np.abs(P[1])) + P[2]*np.exp(-X*np.abs(P[3])) + np.abs(P[-1])
        return Y
        
    @staticmethod    
    def _error(P,f,X,Y):
        &#39;&#39;&#39;Photobleaching correction error function&#39;&#39;&#39;
        e = np.sum(np.power(f(X,P)-Y,2))
        return e
            
    def calc_photobl(self, j=None):
        data_corr = np.copy(self.data)
        X = np.arange(self.data.shape[0])
        self.log(&#34;Calculating photobleaching correction, but not applying it.&#34;,True)
        
        if j is None:
            iterate_over = np.arange(self.data.shape[1])
        else:
            try: len(j)
            except: j = [j]
            iterate_over = j 
        
        for k in iterate_over:
            print(&#34;\t&#34;+str(np.around(float(k)/self.data.shape[1],4))+&#34; done.   &#34;,end=&#34;&#34;)
            try:
                self.maxY[k] = np.max(data_corr[:,k])
                Y = data_corr[:,k]/self.maxY[k]
                mask = np.ones_like(Y,dtype=np.bool)
                P = np.array([1.,0.006,1.,0.001,0.2])
                
                it = 0
                while True and it&lt;100:
                    R = minimize(self._error,P,args=(self._double_exp,X[mask],Y[mask]))
                    if np.sum(np.absolute((P-R.x)/P)) &lt; 1e-2: break
                    P = R.x
                    
                    std = np.std(self._double_exp(X[mask],P)-Y[mask])
                    mask[:] = np.absolute(self._double_exp(X,P)-Y) &lt; 2.*std
                    it += 1
                
                self.photobl_p[k] = P    
                print(&#34;\r&#34;,end=&#34;&#34;)
            except Exception as e:
                self.log(&#34;Problems with trace &#34;+str(k)+&#34;: &#34;+str(e))

    def appl_photobl(self, j=None):
        &#39;&#39;&#39;Apply the precomputed photobleaching correction.
        
        Parameters
        ----------
        j: int (optional)
            Neuron to which to apply the correction. If None, the correction 
            will be applied to all the neurons. Default: None.
        &#39;&#39;&#39; 
        
        self.log(&#34;Applying the photobleaching correction.&#34;,True)
        X = np.arange(self.data.shape[0])
        if j is None:
            iterate_over = np.arange(self.data.shape[1])
        else:
            try: len(j)
            except: j = [j]
            iterate_over = j
            
        for k in iterate_over:
            data_photobleach_fit = self._double_exp(X,self.photobl_p[k])*self.maxY[k]
            self.data[:,k] /= (1.+data_photobleach_fit)
            
    #def get_photobl_fit(self, X, k=None):
    
    def corr_inst_photobl(self, j=None, poly_width=111, photobl_duration=3, min_distance=30):

        if j is None:
            iterate_over = np.arange(self.data.shape[1])
        else:
            try: len(j)
            except: j = [j]
            iterate_over = j
            
        # Calculate derivative (and diff, will be useful later)
        deriv = np.zeros((self.data.shape[0],len(iterate_over)))
        diff = np.zeros((self.data.shape[0],len(iterate_over)))
        derker = -sg.get_1D_filter(poly_width,3,1)        
        for i in np.arange(len(iterate_over)):
            k = iterate_over[i]
            deriv[:,i] = np.convolve(derker,self.data[:,k],mode=&#34;same&#34;)
            diff[:-1,i] = np.diff(self.data[:,k])
            
        # Find where the derivative departs from normal behavior    
        medderiv = np.median(deriv[poly_width:-poly_width],axis=0)
        stdderiv = np.std(deriv[poly_width:-poly_width],axis=0)
        
        for i in np.arange(len(iterate_over)):
            k = iterate_over[i]
            i_pb = np.where(deriv[poly_width:-poly_width,i]&lt;medderiv[i]-3*stdderiv[i])[0]+poly_width
            
            prev_jump_pos = -100*min_distance
            if len(i_pb)&gt;0:
                # Find contiguous regions where the derivative is too negative
                splt = np.where(np.diff(i_pb)&gt;1)[0]+1
                splt = np.append(0,splt)
                splt = np.append(splt,-1)
                for q in np.arange(len(splt)-1):
                    # Find the &#34;real&#34; center of the jump 
                    idx0 = i_pb[splt[q]]
                    idx1 = i_pb[splt[q+1]]
                    if idx1&gt;(idx0+1):
                        #jump_pos_poly = np.argmin(deriv[idx0:idx1,i])+idx0
                        jump_pos = np.argmin(diff[idx0:idx1,i])+idx0
                    else:
                        jump_pos = idx0
                    
                    # Sometimes a region that should be contiguous is split.
                    # If two detected jumps are too close they are likely
                    # originating from this situation, so don&#39;t double count
                    # them.
                    if jump_pos&lt;(prev_jump_pos+min_distance): continue
                    prev_jump_pos = jump_pos
                    
                    # Calculate the amplitude of the jump
                    jump = np.sum(deriv[jump_pos-poly_width//2:jump_pos+poly_width//2,i])
                    
                    # Calculate the factor by which the post-jump data needs to 
                    # be multiplied to be corrected
                    # Pre-jump value: could be something more fancy since you&#39;re
                    # doing polynomial interpolation
                    pre = np.median(self.data[jump_pos-10:jump_pos,k])
                    mult = pre/(pre+jump)
                    
                    self.data[jump_pos+photobl_duration:,k] *= mult
                
        
    
    ##### Additional Capabilities #####
    
    def trim(self,stride_name, adjust = None):
        &#39;&#39;&#39;If the signal is an irregular array, trim it to make the regularize
        the stride along the irregular axis.
        
        Parameters
        ----------
        stride_name: string
            Name of the stride along which to trim.
        adjust: int
            Number of points to average to subtract the background.
            
        Returns
        -------
        trimmed: irregular array
            Irregular array that has now effectively a regular stride. 
            trimmed.data can now be copied and reshaped into a multidimensional
            numpy array.        
        &#39;&#39;&#39;
        
        try:
            start = self.data.firstIndex[stride_name];
            strideLength = np.diff(start);
        except:
            print(&#39;Trim unsuccesful, signal has no strides by the name &#34;&#39; + stride_name + &#39;&#34;.&#39;)
            quit()
        
        mask = np.ones(strideLength.shape, dtype = bool);
        mask[self.which_skip[stride_name]] = False;
        min_len = np.min(strideLength[mask])
        
        temp_data = np.ones((1,self.data.shape[1]))
        temp_nan = np.ones((1,self.data.shape[1]))
        
        for stPt in start[np.append(mask,False)]:
            if adjust == None: adj = 0;
            else: adj = np.mean(self.data[stPt:stPt+adjust],axis=0);
            temp_data = np.vstack((temp_data,self.data[stPt:stPt+min_len]-adj));
            temp_nan = np.vstack((temp_nan,self.nan_mask[stPt:stPt+min_len]));
        temp_data = np.copy(temp_data[1:])
        temp_nan = np.copy(temp_nan[1:])
        
        temp_strides = (np.ones_like(strideLength[mask])*min_len)
        #temp_strides = (np.ones_like(strideLength)*min_len)
        # print(&#39;trimmed strides&#39;,temp_strides)
        
        trimmed = self.copy()
        trimmed.data = irrarray(temp_data, [temp_strides], strideNames=[stride_name])
        trimmed.nan_mask = irrarray(temp_nan, [temp_strides], strideNames=[stride_name])
        trimmed.which_skip = dict({stride_name : []});
        
        return trimmed
        
    def average(self,stride_name, adjust = None):
        &#39;&#39;&#39;Average the signal over an irregular stride. The function first
        obtains the trimmed version of the array along that stride, subtracts
        the background, and averages across the events.
        
        Parameters
        ----------
        stride_name: str
            Name of the irregular stride.
        adjust: int
            Number of points to average for the background subtraction.
            
        Returns
        -------
        avg: numpy array
            Array containing the average over the specified stride.
        
        &#39;&#39;&#39;
        
        # adjust tells you how many points to average as a baseline to subtract out
        try:
            trimmed = self.trim(stride_name, adjust = adjust);
        except:
            print(&#39;Average unsuccessful, signal has no strides by the name &#34;&#39; + stride_name + &#39;&#34;.&#39;)
            quit()
        length = trimmed.data.firstIndex[stride_name][1];
        numStrides = trimmed.data.firstIndex[stride_name].size-1
        temp = np.reshape(trimmed.data,(numStrides,length,trimmed.data.shape[1])) 
        avg = np.mean(temp,axis = 0)
        return avg
        
    def get_loc_std(self,window=8):
        loc_std = np.zeros(self.data.shape[1])
        for j in np.arange(self.data.shape[1]):
            loc_std[j] = np.sqrt(np.median(np.var(self.rolling_window(self.data[:,j], window), axis=-1)))
            
        return loc_std
    
    ##### Underbelly Functions #####
    
    def copy(self):
        return deepcopy(self)
        
    def __getitem__(self, i):
        &#39;&#39;&#39;Allow for direct indexing of the class to access the data.&#39;&#39;&#39;
        return self.data.__getitem__(i)
        
    def __setitem__(self, i, value):
        &#39;&#39;&#39;Allow for direct indexing of the class to write in the data.&#39;&#39;&#39;
        self.data.__setitem__(i,value)
        
    def __call__(self, *args, **kwargs):
        &#39;&#39;&#39;Upon call, use the __call__ method of the data irrarray.&#39;&#39;&#39;
        return self.data.__call__(*args, **kwargs)
        
        
    @staticmethod
    def rolling_window(a, window):
        pad = np.ones(len(a.shape), dtype=np.int32)
        pad[-1] = window-1
        pad = list(zip(pad, np.zeros(len(a.shape), dtype=np.int32)))
        a = np.pad(a, pad,mode=&#39;reflect&#39;)
        shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
        strides = a.strides + (a.strides[-1],)
        return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="wormdatamodel.signal.signal.Signal.nan_mask"><code class="name">var <span class="ident">nan_mask</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.data"><code class="name">var <span class="ident">data</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.info"><code class="name">var <span class="ident">info</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.which_skip"><code class="name">var <span class="ident">which_skip</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.maxY"><code class="name">var <span class="ident">maxY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.photobl_p"><code class="name">var <span class="ident">photobl_p</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.photobl_n_params"><code class="name">var <span class="ident">photobl_n_params</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.logbook"><code class="name">var <span class="ident">logbook</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.description"><code class="name">var <span class="ident">description</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.filename"><code class="name">var <span class="ident">filename</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="wormdatamodel.signal.signal.Signal.from_file"><code class="name flex">
<span>def <span class="ident">from_file</span></span>(<span>folder, filename, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates an instance of the class loading the data from file. If
filename ends with ".txt" the Signal object will be created from the
raw data. If the filename ends with ".pickle", the function will load
the data from the pickled file. If the filename does not end with either
extension, the data will be loaded from the pickled file filename.pickle
if present, otherwise from the raw filename.txt. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>folder</code></strong> :&ensp;<code>str</code></dt>
<dd>Folder containing the file.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the file containing the signal array.</dd>
<dt><strong><code>*args</code></strong>, <strong><code>**kwargs</code></strong></dt>
<dd>Any other parameter to be passed to the constructor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_file(cls,folder,filename,*args,**kwargs):
    &#39;&#39;&#39;Creates an instance of the class loading the data from file. If 
    filename ends with &#34;.txt&#34; the Signal object will be created from the 
    raw data. If the filename ends with &#34;.pickle&#34;, the function will load
    the data from the pickled file. If the filename does not end with either
    extension, the data will be loaded from the pickled file filename.pickle
    if present, otherwise from the raw filename.txt. 
    
    Parameters
    ----------
    folder: str
        Folder containing the file.
    filename: str
        Name of the file containing the signal array.
    *args, **kwargs
        Any other parameter to be passed to the constructor.
    &#39;&#39;&#39;
    
    if filename.split(&#34;.&#34;)[-1] == &#34;txt&#34;: 
        # read in data; rows = time, columns = neuron
        data, info = wormdm.signal.from_file(folder,filename)
        # adjusting the shape so that even if only one neuron, still has &#34;columns&#34;
        try:
            data.shape[1]
        except:
            data = np.copy(np.reshape(data,(data.shape[0],1)))
        
        inst = cls(data,info,&#34;.&#34;.join(filename.split(&#34;.&#34;)[:-1]),*args,**kwargs)
        return inst
        
    elif filename.split(&#34;.&#34;)[-1] == &#34;pickle&#34;:
        f = open(folder+filename,&#34;rb&#34;)
        inst = pickle.load(f)
        f.close()
        return inst
    else:
        if os.path.isfile(folder+filename+&#34;.pickle&#34;):
            f = open(folder+filename+&#34;.pickle&#34;,&#34;rb&#34;)
            inst = pickle.load(f)
            f.close()
            return inst
        elif os.path.isfile(folder+filename+&#34;.txt&#34;):
            data, info = wormdm.signal.from_file(folder,filename)
            try:
                data.shape[1]
            except:
                data = np.copy(np.reshape(data,(data.shape[0],1)))
        
            inst = cls(data,info,filename,*args,**kwargs)
            return inst
        else:
            print(folder+filename+&#34; is not present.&#34;)
            quit()</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.from_signal_and_reference"><code class="name flex">
<span>def <span class="ident">from_signal_and_reference</span></span>(<span>folder, uncorr_signal_fname, reference_fname, method=0.0, strides=[], stride_names=[], stride_skip=[])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_signal_and_reference(cls, folder, uncorr_signal_fname, reference_fname, method=0.0, strides = [], stride_names = [], stride_skip = []):
    
    # If the filename does not have any extension assign one. If both pickle
    # file exist, then load the pickles if the pickle file is newer than
    # the txt, otherwise load the raw txt.
    if len(uncorr_signal_fname.split(&#34;.&#34;)) == 1:
        if os.path.isfile(folder+uncorr_signal_fname+&#34;.pickle&#34;) and os.path.isfile(folder+reference_fname+&#34;.pickle&#34;):
            if os.path.getmtime(folder+uncorr_signal_fname+&#34;.pickle&#34;) &gt; os.path.getmtime(folder+uncorr_signal_fname+&#34;.txt&#34;):
                uncorr_signal_fname += &#34;.pickle&#34;
                reference_fname += &#34;.pickle&#34;
            else:
                uncorr_signal_fname += &#34;.txt&#34;
                reference_fname += &#34;.txt&#34;
        else:
            uncorr_signal_fname += &#34;.txt&#34;
            reference_fname += &#34;.txt&#34;
    
    # Extract description and extensions from the filenames
    uncorr_signal_ext = uncorr_signal_fname.split(&#34;.&#34;)[-1]
    uncorr_signal_descr = uncorr_signal_fname.split(&#34;.&#34;)[:-1]
    reference_ext = reference_fname.split(&#34;.&#34;)[-1]
    reference_descr = reference_fname.split(&#34;.&#34;)[:-1]
    
    # If the two extensions are different, quit.
    if uncorr_signal_ext != reference_ext:
        print(&#34;Provide the source of the uncorrected signal and reference from the same file format.&#34;)
        quit()
    
    # If loading from the raw txt files, preprocess. If loading from the 
    # pickles, do not preprocess.
    if uncorr_signal_ext == &#34;txt&#34;:
        uncorr_signal = cls.from_file(folder, uncorr_signal_fname, nan_interp=True, smooth=False, photobl_calc=True, photobl_appl=False, strides = [], stride_names = [], stride_skip = [])
        reference = cls.from_file(folder, reference_fname, nan_interp=True, smooth=False, photobl_calc=True, photobl_appl=False, corr_inst_photobl=True, strides = [], stride_names = [], stride_skip = [])
        
        # Save the preprocessed files.
        uncorr_signal.to_file(folder,&#34;.&#34;.join([uncorr_signal_fname.split(&#34;.&#34;)[0],&#34;pickle&#34;]) )
        reference.to_file(folder,&#34;.&#34;.join([reference_fname.split(&#34;.&#34;)[0],&#34;pickle&#34;]))
        
    elif uncorr_signal_ext == &#34;pickle&#34;:
        uncorr_signal = cls.from_file(folder, uncorr_signal_fname, preprocess=False)
        reference = cls.from_file(folder, reference_fname, preprocess=False)
        if os.path.isfile(folder+cls.filename):
            signal = cls.from_file(folder,cls.filename)
            if signal.info[&#34;correction_method&#34;] == method: 
                print(&#34;Using pickled signal.&#34;)
                return signal
    
    # Merge the infos from the source Signal objects
    info = reference.info.copy()
    info[&#34;uncorr_signal&#34;] = uncorr_signal.info
    info[&#34;reference&#34;] = reference.info 
    info[&#34;correction_method&#34;] = method
    
    # Compute the corrected signal based on one of the methods available.
    signal_d = np.zeros_like(reference.data)
    if method == 0.0:
        # Standard ratiometric
        X = np.arange(uncorr_signal.data.shape[0])
        for k in np.arange(uncorr_signal.data.shape[1]):
            unc_sig_pb = uncorr_signal._double_exp(X,uncorr_signal.photobl_p[k])
            ref_pb = reference._double_exp(X,reference.photobl_p[k])
            #signal_d[:,k] = (uncorr_signal.data[:,k])/(reference.data[:,k])*(ref_pb*reference.maxY[k])/(unc_sig_pb*uncorr_signal.maxY[k])
            # Removing the normalizations, I want it to have the same 
            # amplitude as the raw GCaMP fluorescence, so that it&#39;s kind of 
            # not cell-specific.
            signal_d[:,k] = (uncorr_signal.data[:,k])/(reference.data[:,k])*(ref_pb*reference.maxY[k])/(unc_sig_pb)
    elif method==1.5:
        # Derivative-based, version 1.5
        X = np.arange(uncorr_signal.data.shape[0])
        for k in np.arange(uncorr_signal.data.shape[1]):
            P = reference.photobl_p
            Y = cls._double_exp(X,P[k])
            prop = (Y[1:]-P[k,-1])/(Y[:-1]-P[k,-1])
            oneplusdelta = (reference[1:,k]/reference[:-1,k])*prop
            oneplusd = uncorr_signal[1:,k]/uncorr_signal[:-1,k]/oneplusdelta
            signal_d[0,k] = uncorr_signal[0,k]
            for i in np.arange(uncorr_signal.data.shape[0]-1):
                signal_d[i+1,k] = signal_d[i,k]*oneplusd[i]
    elif method == 1.6:
        # Derivative-based, verions 1.6
        X = np.arange(uncorr_signal.data.shape[0])
        for k in np.arange(uncorr_signal.data.shape[1]):
            P = reference.photobl_p
            Y = cls._double_exp(X,P[k])
            prop = (Y[1:]-P[k,-1])/(Y[:-1]-P[k,-1])
            whatRshouldbe = (reference[:-1,k]-P[k,-1])*prop+P[k,-1]
            oneplusdelta = reference[1:,k]/whatRshouldbe
            oneplusd = (uncorr_signal[1:,k]+100)/(uncorr_signal[:-1,k]+100)/oneplusdelta
            signal_d[0,k] = uncorr_signal[0,k]+100
            for i in np.arange(uncorr_signal.data.shape[0]-1):
                signal_d[i+1,k] = signal_d[i,k]*oneplusd[i]
    elif method == 2.0:
        # ICA
        X = np.arange(uncorr_signal.data.shape[0])
        rlocstd = reference.get_loc_std(8)
        unclocstd = uncorr_signal.get_loc_std()
        trasformer = FastICA(n_components=2, random_state=0)
        for k in np.arange(uncorr_signal.data.shape[1]):
            unc_sig_pb = uncorr_signal._double_exp(X,uncorr_signal.photobl_p[k])
            ref_pb = reference._double_exp(X,reference.photobl_p[k])
            mixed = np.array([uncorr_signal.data[:,k]/unc_sig_pb/unclocstd[k],reference.data[:,k]/ref_pb/rlocstd[k]]).T
            signal_d[:,k] = mixed[:,0]
    
    
    if method == 1.6: photobl_calc = photobl_appl = True
    else: photobl_calc = photobl_appl = False
    #photobl_calc = photobl_appl = False
    
    # Create the Signal object with the corrected signal.
    signal = cls(signal_d, info, description=&#34;signal&#34;, strides=strides, stride_names=stride_names, stride_skip=stride_skip, photobl_calc=photobl_calc, photobl_appl=photobl_appl)
        
    # Transfer logbooks from the original Signal objects
    signal.logbook += &#34;Uncorrected signal log:\n&#34;+&#34;\t&#34;+&#34;\n\t&#34;.join(uncorr_signal.logbook.split(&#34;\n&#34;))[:-2]+&#34;\n&#34;
    signal.logbook += &#34;Reference log:\n&#34;+&#34;\t&#34;+&#34;\n\t&#34;.join(reference.logbook.split(&#34;\n&#34;))[:-2]+&#34;\n&#34;
    
    # Transfer nanmask
    signal.nan_mask = np.logical_or(reference.nan_mask,signal.nan_mask)
        
    signal.to_file(folder,cls.filename)
        
    return signal</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.rolling_window"><code class="name flex">
<span>def <span class="ident">rolling_window</span></span>(<span>a, window)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def rolling_window(a, window):
    pad = np.ones(len(a.shape), dtype=np.int32)
    pad[-1] = window-1
    pad = list(zip(pad, np.zeros(len(a.shape), dtype=np.int32)))
    a = np.pad(a, pad,mode=&#39;reflect&#39;)
    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
    strides = a.strides + (a.strides[-1],)
    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="wormdatamodel.signal.signal.Signal.to_file"><code class="name flex">
<span>def <span class="ident">to_file</span></span>(<span>self, folder, filename)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_file(self,folder,filename):
    if filename.split(&#34;.&#34;)[-1] != &#34;pickle&#34;:
        filename += &#34;.pickle&#34;
    pickle_file = open(folder+filename,&#34;wb&#34;)
    pickle.dump(self,pickle_file)
    pickle_file.close()</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.log"><code class="name flex">
<span>def <span class="ident">log</span></span>(<span>self, s=None, print_to_terminal=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Write an entry in the internal log and, if requested, print the same
entry to terminal. In the log, the entry will start with the
current time.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>s</code></strong> :&ensp;<code>string</code></dt>
<dd>Text of the entry.</dd>
<dt><strong><code>print_to_terminal</code></strong> :&ensp;<code>boolean</code></dt>
<dd>If True, the entry will also be printed to terminal. Default: True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log(self, s = None, print_to_terminal = True):
    &#39;&#39;&#39;Write an entry in the internal log and, if requested, print the same
    entry to terminal. In the log, the entry will start with the 
    current time.
    
    Parameters
    ----------
    s: string
        Text of the entry.
    print_to_terminal: boolean
        If True, the entry will also be printed to terminal. Default: True.

    Returns
    -------
    None
    &#39;&#39;&#39;
    if s is not None:
        now = datetime.now()
        dt = now.strftime(&#34;%Y-%m-%d %H:%M:%S: &#34;)
        self.logbook += (dt+s+&#34;\n&#34;)
        if print_to_terminal:
            print(&#34;Signal &#34;+self.description+&#34;: &#34;+s)</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.interpolate_nans"><code class="name flex">
<span>def <span class="ident">interpolate_nans</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace nans with an interpolated value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def interpolate_nans(self):
    &#39;&#39;&#39;Replace nans with an interpolated value.&#39;&#39;&#39;
    
    self.log(&#34;Replacing nans with the interpolated value.&#34;,False)
    interpolated = np.copy(self.data)
    
    for i in np.arange(self.data.shape[1]):
        # nans: location of nans
        # x: function that finds the non-zero entries
        nans, x = self.nan_mask[:,i], lambda z: z.nonzero()[0]
        try:
            interpolated[nans,i] = np.interp(x(nans), x(~nans), self.data[~nans,i])
        except:
            pass
    
    return interpolated</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.smooth"><code class="name flex">
<span>def <span class="ident">smooth</span></span>(<span>self, n)</span>
</code></dt>
<dd>
<div class="desc"><p>Smooth the signal with a rectangular filter.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Width of the rectangular filter.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def smooth(self, n):
    &#39;&#39;&#39;Smooth the signal with a rectangular filter.
    
    Parameters
    ----------
    n: int
        Width of the rectangular filter.        
    &#39;&#39;&#39;
    self.log(&#34;Smoothing signal with a window of &#34;+str(n)+&#34; points.&#34;,False)
    
    sm = np.ones(n)/n
    smoothed = np.copy(self.data)    
    
    for i in np.arange(self.data.shape[1]):
        smoothed[:,i] = np.convolve(self.data[:,i],sm,mode=&#34;same&#34;)
    
    return smoothed</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.calc_photobl"><code class="name flex">
<span>def <span class="ident">calc_photobl</span></span>(<span>self, j=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_photobl(self, j=None):
    data_corr = np.copy(self.data)
    X = np.arange(self.data.shape[0])
    self.log(&#34;Calculating photobleaching correction, but not applying it.&#34;,True)
    
    if j is None:
        iterate_over = np.arange(self.data.shape[1])
    else:
        try: len(j)
        except: j = [j]
        iterate_over = j 
    
    for k in iterate_over:
        print(&#34;\t&#34;+str(np.around(float(k)/self.data.shape[1],4))+&#34; done.   &#34;,end=&#34;&#34;)
        try:
            self.maxY[k] = np.max(data_corr[:,k])
            Y = data_corr[:,k]/self.maxY[k]
            mask = np.ones_like(Y,dtype=np.bool)
            P = np.array([1.,0.006,1.,0.001,0.2])
            
            it = 0
            while True and it&lt;100:
                R = minimize(self._error,P,args=(self._double_exp,X[mask],Y[mask]))
                if np.sum(np.absolute((P-R.x)/P)) &lt; 1e-2: break
                P = R.x
                
                std = np.std(self._double_exp(X[mask],P)-Y[mask])
                mask[:] = np.absolute(self._double_exp(X,P)-Y) &lt; 2.*std
                it += 1
            
            self.photobl_p[k] = P    
            print(&#34;\r&#34;,end=&#34;&#34;)
        except Exception as e:
            self.log(&#34;Problems with trace &#34;+str(k)+&#34;: &#34;+str(e))</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.appl_photobl"><code class="name flex">
<span>def <span class="ident">appl_photobl</span></span>(<span>self, j=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply the precomputed photobleaching correction.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>j</code></strong> :&ensp;<code>int (optional)</code></dt>
<dd>Neuron to which to apply the correction. If None, the correction
will be applied to all the neurons. Default: None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def appl_photobl(self, j=None):
    &#39;&#39;&#39;Apply the precomputed photobleaching correction.
    
    Parameters
    ----------
    j: int (optional)
        Neuron to which to apply the correction. If None, the correction 
        will be applied to all the neurons. Default: None.
    &#39;&#39;&#39; 
    
    self.log(&#34;Applying the photobleaching correction.&#34;,True)
    X = np.arange(self.data.shape[0])
    if j is None:
        iterate_over = np.arange(self.data.shape[1])
    else:
        try: len(j)
        except: j = [j]
        iterate_over = j
        
    for k in iterate_over:
        data_photobleach_fit = self._double_exp(X,self.photobl_p[k])*self.maxY[k]
        self.data[:,k] /= (1.+data_photobleach_fit)</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.corr_inst_photobl"><code class="name flex">
<span>def <span class="ident">corr_inst_photobl</span></span>(<span>self, j=None, poly_width=111, photobl_duration=3, min_distance=30)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def corr_inst_photobl(self, j=None, poly_width=111, photobl_duration=3, min_distance=30):

    if j is None:
        iterate_over = np.arange(self.data.shape[1])
    else:
        try: len(j)
        except: j = [j]
        iterate_over = j
        
    # Calculate derivative (and diff, will be useful later)
    deriv = np.zeros((self.data.shape[0],len(iterate_over)))
    diff = np.zeros((self.data.shape[0],len(iterate_over)))
    derker = -sg.get_1D_filter(poly_width,3,1)        
    for i in np.arange(len(iterate_over)):
        k = iterate_over[i]
        deriv[:,i] = np.convolve(derker,self.data[:,k],mode=&#34;same&#34;)
        diff[:-1,i] = np.diff(self.data[:,k])
        
    # Find where the derivative departs from normal behavior    
    medderiv = np.median(deriv[poly_width:-poly_width],axis=0)
    stdderiv = np.std(deriv[poly_width:-poly_width],axis=0)
    
    for i in np.arange(len(iterate_over)):
        k = iterate_over[i]
        i_pb = np.where(deriv[poly_width:-poly_width,i]&lt;medderiv[i]-3*stdderiv[i])[0]+poly_width
        
        prev_jump_pos = -100*min_distance
        if len(i_pb)&gt;0:
            # Find contiguous regions where the derivative is too negative
            splt = np.where(np.diff(i_pb)&gt;1)[0]+1
            splt = np.append(0,splt)
            splt = np.append(splt,-1)
            for q in np.arange(len(splt)-1):
                # Find the &#34;real&#34; center of the jump 
                idx0 = i_pb[splt[q]]
                idx1 = i_pb[splt[q+1]]
                if idx1&gt;(idx0+1):
                    #jump_pos_poly = np.argmin(deriv[idx0:idx1,i])+idx0
                    jump_pos = np.argmin(diff[idx0:idx1,i])+idx0
                else:
                    jump_pos = idx0
                
                # Sometimes a region that should be contiguous is split.
                # If two detected jumps are too close they are likely
                # originating from this situation, so don&#39;t double count
                # them.
                if jump_pos&lt;(prev_jump_pos+min_distance): continue
                prev_jump_pos = jump_pos
                
                # Calculate the amplitude of the jump
                jump = np.sum(deriv[jump_pos-poly_width//2:jump_pos+poly_width//2,i])
                
                # Calculate the factor by which the post-jump data needs to 
                # be multiplied to be corrected
                # Pre-jump value: could be something more fancy since you&#39;re
                # doing polynomial interpolation
                pre = np.median(self.data[jump_pos-10:jump_pos,k])
                mult = pre/(pre+jump)
                
                self.data[jump_pos+photobl_duration:,k] *= mult</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.trim"><code class="name flex">
<span>def <span class="ident">trim</span></span>(<span>self, stride_name, adjust=None)</span>
</code></dt>
<dd>
<div class="desc"><p>If the signal is an irregular array, trim it to make the regularize
the stride along the irregular axis.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>stride_name</code></strong> :&ensp;<code>string</code></dt>
<dd>Name of the stride along which to trim.</dd>
<dt><strong><code>adjust</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points to average to subtract the background.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>trimmed</code></strong> :&ensp;<code>irregular array</code></dt>
<dd>Irregular array that has now effectively a regular stride.
trimmed.data can now be copied and reshaped into a multidimensional
numpy array.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim(self,stride_name, adjust = None):
    &#39;&#39;&#39;If the signal is an irregular array, trim it to make the regularize
    the stride along the irregular axis.
    
    Parameters
    ----------
    stride_name: string
        Name of the stride along which to trim.
    adjust: int
        Number of points to average to subtract the background.
        
    Returns
    -------
    trimmed: irregular array
        Irregular array that has now effectively a regular stride. 
        trimmed.data can now be copied and reshaped into a multidimensional
        numpy array.        
    &#39;&#39;&#39;
    
    try:
        start = self.data.firstIndex[stride_name];
        strideLength = np.diff(start);
    except:
        print(&#39;Trim unsuccesful, signal has no strides by the name &#34;&#39; + stride_name + &#39;&#34;.&#39;)
        quit()
    
    mask = np.ones(strideLength.shape, dtype = bool);
    mask[self.which_skip[stride_name]] = False;
    min_len = np.min(strideLength[mask])
    
    temp_data = np.ones((1,self.data.shape[1]))
    temp_nan = np.ones((1,self.data.shape[1]))
    
    for stPt in start[np.append(mask,False)]:
        if adjust == None: adj = 0;
        else: adj = np.mean(self.data[stPt:stPt+adjust],axis=0);
        temp_data = np.vstack((temp_data,self.data[stPt:stPt+min_len]-adj));
        temp_nan = np.vstack((temp_nan,self.nan_mask[stPt:stPt+min_len]));
    temp_data = np.copy(temp_data[1:])
    temp_nan = np.copy(temp_nan[1:])
    
    temp_strides = (np.ones_like(strideLength[mask])*min_len)
    #temp_strides = (np.ones_like(strideLength)*min_len)
    # print(&#39;trimmed strides&#39;,temp_strides)
    
    trimmed = self.copy()
    trimmed.data = irrarray(temp_data, [temp_strides], strideNames=[stride_name])
    trimmed.nan_mask = irrarray(temp_nan, [temp_strides], strideNames=[stride_name])
    trimmed.which_skip = dict({stride_name : []});
    
    return trimmed</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.average"><code class="name flex">
<span>def <span class="ident">average</span></span>(<span>self, stride_name, adjust=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Average the signal over an irregular stride. The function first
obtains the trimmed version of the array along that stride, subtracts
the background, and averages across the events.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>stride_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the irregular stride.</dd>
<dt><strong><code>adjust</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points to average for the background subtraction.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>avg</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>Array containing the average over the specified stride.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def average(self,stride_name, adjust = None):
    &#39;&#39;&#39;Average the signal over an irregular stride. The function first
    obtains the trimmed version of the array along that stride, subtracts
    the background, and averages across the events.
    
    Parameters
    ----------
    stride_name: str
        Name of the irregular stride.
    adjust: int
        Number of points to average for the background subtraction.
        
    Returns
    -------
    avg: numpy array
        Array containing the average over the specified stride.
    
    &#39;&#39;&#39;
    
    # adjust tells you how many points to average as a baseline to subtract out
    try:
        trimmed = self.trim(stride_name, adjust = adjust);
    except:
        print(&#39;Average unsuccessful, signal has no strides by the name &#34;&#39; + stride_name + &#39;&#34;.&#39;)
        quit()
    length = trimmed.data.firstIndex[stride_name][1];
    numStrides = trimmed.data.firstIndex[stride_name].size-1
    temp = np.reshape(trimmed.data,(numStrides,length,trimmed.data.shape[1])) 
    avg = np.mean(temp,axis = 0)
    return avg</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.get_loc_std"><code class="name flex">
<span>def <span class="ident">get_loc_std</span></span>(<span>self, window=8)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_loc_std(self,window=8):
    loc_std = np.zeros(self.data.shape[1])
    for j in np.arange(self.data.shape[1]):
        loc_std[j] = np.sqrt(np.median(np.var(self.rolling_window(self.data[:,j], window), axis=-1)))
        
    return loc_std</code></pre>
</details>
</dd>
<dt id="wormdatamodel.signal.signal.Signal.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self):
    return deepcopy(self)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="wormdatamodel.signal" href="index.html">wormdatamodel.signal</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="wormdatamodel.signal.signal.Signal" href="#wormdatamodel.signal.signal.Signal">Signal</a></code></h4>
<ul class="">
<li><code><a title="wormdatamodel.signal.signal.Signal.from_file" href="#wormdatamodel.signal.signal.Signal.from_file">from_file</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.from_signal_and_reference" href="#wormdatamodel.signal.signal.Signal.from_signal_and_reference">from_signal_and_reference</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.rolling_window" href="#wormdatamodel.signal.signal.Signal.rolling_window">rolling_window</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.to_file" href="#wormdatamodel.signal.signal.Signal.to_file">to_file</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.log" href="#wormdatamodel.signal.signal.Signal.log">log</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.interpolate_nans" href="#wormdatamodel.signal.signal.Signal.interpolate_nans">interpolate_nans</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.smooth" href="#wormdatamodel.signal.signal.Signal.smooth">smooth</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.calc_photobl" href="#wormdatamodel.signal.signal.Signal.calc_photobl">calc_photobl</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.appl_photobl" href="#wormdatamodel.signal.signal.Signal.appl_photobl">appl_photobl</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.corr_inst_photobl" href="#wormdatamodel.signal.signal.Signal.corr_inst_photobl">corr_inst_photobl</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.trim" href="#wormdatamodel.signal.signal.Signal.trim">trim</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.average" href="#wormdatamodel.signal.signal.Signal.average">average</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.get_loc_std" href="#wormdatamodel.signal.signal.Signal.get_loc_std">get_loc_std</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.copy" href="#wormdatamodel.signal.signal.Signal.copy">copy</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.nan_mask" href="#wormdatamodel.signal.signal.Signal.nan_mask">nan_mask</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.data" href="#wormdatamodel.signal.signal.Signal.data">data</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.info" href="#wormdatamodel.signal.signal.Signal.info">info</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.which_skip" href="#wormdatamodel.signal.signal.Signal.which_skip">which_skip</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.maxY" href="#wormdatamodel.signal.signal.Signal.maxY">maxY</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.photobl_p" href="#wormdatamodel.signal.signal.Signal.photobl_p">photobl_p</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.photobl_n_params" href="#wormdatamodel.signal.signal.Signal.photobl_n_params">photobl_n_params</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.logbook" href="#wormdatamodel.signal.signal.Signal.logbook">logbook</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.description" href="#wormdatamodel.signal.signal.Signal.description">description</a></code></li>
<li><code><a title="wormdatamodel.signal.signal.Signal.filename" href="#wormdatamodel.signal.signal.Signal.filename">filename</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>